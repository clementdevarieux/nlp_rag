{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from src.config import DOCUMENTS_DIR",
   "id": "f4bac71c2b369df3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "path = Path(DOCUMENTS_DIR)",
   "id": "117fced5726acddf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "texts = []\n",
    "for filename in path.glob(\"*.md\"):\n",
    "    with open(filename) as f:\n",
    "        texts.append(f.read())\n",
    "\n",
    "texts[0]"
   ],
   "id": "ad934203d667e344",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# chunk",
   "id": "e87f201acdff3770"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def parse_class(text):\n",
    "    chunks = re.split(\"##\", text)\n",
    "    title = chunks[0].split(\"#\")[0]\n",
    "    return {\"title\": title, \"chunks\": chunks}"
   ],
   "id": "db7459274ad237af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def parse_class_add_title(text):\n",
    "    chunks = text.split(\"##\")\n",
    "    title =  chunks[0].split(\"#\")[0]\n",
    "    return {\"title\": title, \"chunks\": [f\"{title}: {chunk}\" for chunk in chunks]}"
   ],
   "id": "622504bfc69bb106",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chunks = sum((parse_class_add_title(txt)[\"chunks\"] for txt in texts), [])",
   "id": "9a8349d6c1decf91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chunks",
   "id": "1bd126c93fb7114f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Embedding",
   "id": "654f99942b4024a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from FlagEmbedding import FlagModel",
   "id": "3126c31fd4c476f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = FlagModel(\n",
    "    'BAAI/bge-base-en-v1.5',\n",
    "    query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n",
    "    use_fp16=True,\n",
    ")"
   ],
   "id": "1738b71a2d1f34b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "corpus_embedding = model.encode(chunks)",
   "id": "44ae76cba9287e05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "queries = [\"How to make a sum of tensor\"]\n",
   "id": "bd90c0a8ffc611e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "query_embedding = model.encode(queries)",
   "id": "43934760b3c800f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sim_scores = query_embedding @ corpus_embedding.T",
   "id": "6d53eb921ab892c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for query, score in zip(queries, sim_scores):\n",
    "    print(\" ---- \")\n",
    "    print(\"Query: \", query)\n",
    "    indexes = np.argsort(score)[-5:]\n",
    "    print(\"Sources:\")\n",
    "    for i, idx in enumerate(reversed(indexes)):\n",
    "        if score[idx] > .5:\n",
    "            print(f\"{i+1} -- similarity {score[idx]:.2f} -- \\\"\", chunks[idx], '\"')"
   ],
   "id": "a0ff44d9eaab5259",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# eval retrieval ",
   "id": "bc4ca5597ec81751"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "list_question = [\"How to make a sum of tensor\", \"what is burn\"]\n",
    "list_answer = [\"fn add\", \"crate\"]"
   ],
   "id": "93f82b0f62efd0a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MRR ",
   "id": "13f278e1832474da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df  = pd.DataFrame({\"question\": list_question, \"answer\": list_answer})",
   "id": "9d0d3e7527bd2369",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "6cdb3a334d7e14ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_embedding = model.encode(list(df[\"question\"]))\n",
    "query_embedding"
   ],
   "id": "fbf204ae45b7f1ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "acceptable_chunks = []\n",
    "for answer in df[\"answer\"]:\n",
    "    chunks_ok = set(i for i, chunk in enumerate(chunks) if answer in chunk)\n",
    "    acceptable_chunks.append(chunks_ok)\n",
    "acceptable_chunks"
   ],
   "id": "e4a34fe5bac54971",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_mrr(sim_score, acceptable_chunks):\n",
    "    ranks = []\n",
    "    for this_score, this_acceptable_chunks in zip(sim_score, acceptable_chunks):\n",
    "        indexes = reversed(np.argsort(this_score))\n",
    "        rank = 1 + next(i for i, idx in enumerate(indexes) if idx in this_acceptable_chunks)\n",
    "        ranks.append(rank)\n",
    "        \n",
    "    return {\n",
    "        \"score\": sum(1 / r if r < 6 else 0 for r in ranks) / len(ranks),\n",
    "        \"ranks\": ranks,\n",
    "    }"
   ],
   "id": "f8d8b5597f33df2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sim_scores = query_embedding @ corpus_embedding.T",
   "id": "677ad0a2305f5aa5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res = compute_mrr(sim_scores, acceptable_chunks)\n",
    "res[\"score\"]"
   ],
   "id": "2c5cb8da0a852fae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## text generation",
   "id": "1ecdc7c4be003c52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_context(query, corpus, corpus_embeddings):\n",
    "    query_embedding = model.encode([query])\n",
    "    sim_scores = query_embedding @ corpus_embedding.T\n",
    "    indexes = list(np.argsort(sim_scores[0]))[-5:]\n",
    "    return [corpus[i] for i in indexes]"
   ],
   "id": "b242557a23a2091c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_context(\"how to sum two tensor\", chunks, corpus_embedding)",
   "id": "fe1c612e662dcd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# smoll",
   "id": "8c4fad4c65f35a69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "# checkpoint = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
    "\n",
    "device = \"cpu\" # for GPU usage or \"cpu\" for CPU usage\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model_generator = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)"
   ],
   "id": "719721332d1dac7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "58a5a0db72e1d95b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
